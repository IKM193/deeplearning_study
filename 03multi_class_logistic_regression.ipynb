{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03multi_class_logistic_regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuAXT0KZwPFRl8fxVxqaxB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"PxXbFFum3Kgj","executionInfo":{"status":"ok","timestamp":1642173096783,"user_tz":-540,"elapsed":269,"user":{"displayName":"あいうえおTeamF","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaCBWzkYqZqRQYxfC4DkLDypbRuIni4SXpMFm1Ug=s64","userId":"09495778697115388516"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"63f9426b-9c97-43e1-8326-6c2a874232dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch : 1, loss :  100.495\n","epoch : 10, loss :  0.000\n","Prediction matched:  [ True  True  True  True  True]\n"]}],"source":["import numpy as np\n","from sklearn.utils import shuffle\n","\n","class LogisticRegression(object):\n","  '''\n","  (多クラス)ロジスティック回帰\n","  '''\n","  def __init__(self, input_dim, output_dim):\n","    self.input_dim = input_dim\n","    self.W = np.random.normal(size=(input_dim, output_dim))\n","    self.b = np.zeros(output_dim)\n","\n","  def __call__(self, x):\n","    return self.forward(x)\n","\n","  def forward(self, x):\n","    return softmax(np.matmul(x, self.W) + self.b)\n","\n","  def compute_gradients(self, x, t):\n","    y = self.forward(x)\n","    delta = y - t\n","    dW = np.matmul(x.T, delta)\n","    db = np.matmul(np.ones(x.shape[0]), delta)\n","    return dW, db\n","\n","def softmax(x):\n","  return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n","\n","if __name__ == '__main__':\n","  np.random.seed(123)\n","\n","  '''\n","  1. データの準備\n","  '''\n","  M = 2 #入力データの次元\n","  K = 3 #クラス数\n","  n = 100 #クラスごとのデータ数\n","  N = n * K # 全データ数\n","\n","  x1 = np.random.randn(n, M) + np.array([0, 10])\n","  x2 = np.random.randn(n, M) + np.array([5, 5])\n","  x3 = np.random.randn(n, M) + np.array([10, 0])\n","  t1 = np.array([[1, 0, 0] for i in range(n)])\n","  t2 = np.array([[0, 1, 0] for i in range(n)])\n","  t3 = np.array([[0, 0, 1] for i in range(n)])\n","\n","  x = np.concatenate((x1, x2, x3), axis=0)\n","  t = np.concatenate((t1, t2, t3), axis=0)\n","  '''\n","  2. モデルの構築\n","  '''\n","  model = LogisticRegression(input_dim=M, output_dim=K)\n","  '''\n","  3. モデルの学習\n","  '''\n","  def compute_loss(t, y):\n","    return (-t * np.log(y)).sum(axis=1).mean()\n","  \n","  def train_step(x, t):\n","    dW, db = model.compute_gradients(x, t)\n","    model.W = model.W - 0.1 * dW\n","    model.b = model.b - 0.1 * db\n","    loss = compute_loss(t, model(x))\n","    return loss\n","  \n","  epochs = 10\n","  batch_size = 50\n","  n_batches = x.shape[0] // batch_size\n","\n","  for epoch in range(epochs):\n","    train_loss = 0.\n","    x_, t_ = shuffle(x, t)\n","\n","    for n_batch in range(n_batches):\n","      start = n_batch * batch_size\n","      end = start + batch_size\n","\n","      train_loss += train_step(x_[start:end], t_[start:end])\n","    \n","    if epoch % 10 == 0 or epoch == epochs - 1:\n","      print('epoch : {}, loss : {: .3f}' .format(epoch+1, train_loss))                              \n","  '''\n","  #4. モデルの評価\n","  '''\n","  x_, t_ = shuffle(x, t)\n","  preds = model(x_[0:5])\n","  classified =  np.argmax(t_[0:5], axis=1) == np.argmax(preds[0:5], axis=1)\n","  print('Prediction matched: ', classified)"]}]}