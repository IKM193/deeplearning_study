{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02logistic_regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXhK+H4slvj9bnZJd19Jht"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNFVndBXKvNV","executionInfo":{"status":"ok","timestamp":1642075490782,"user_tz":-540,"elapsed":314,"user":{"displayName":"あいうえおTeamF","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaCBWzkYqZqRQYxfC4DkLDypbRuIni4SXpMFm1Ug=s64","userId":"09495778697115388516"}},"outputId":"c6e488a0-2482-43e8-b6a2-df2322266e06"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss:  3.289\n","epoch: 11, loss:  1.893\n","epoch: 21, loss:  1.600\n","epoch: 31, loss:  1.413\n","epoch: 41, loss:  1.264\n","epoch: 51, loss:  1.142\n","epoch: 61, loss:  1.040\n","epoch: 71, loss:  0.954\n","epoch: 81, loss:  0.880\n","epoch: 91, loss:  0.816\n","epoch: 100, loss:  0.766\n","[0 0] =>  0.374\n","[0 1] =>  0.846\n","[1 0] =>  0.890\n","[1 1] =>  0.987\n"]}],"source":["import numpy as np\n","\n","class LogisticRegression(object):\n","  '''\n","  ロジスティック回帰\n","  '''\n","  def __init__(self, input_dim):\n","    self.input_dim = input_dim\n","    self.w = np.random.normal(size=(input_dim,))\n","    self.b = 0.\n","\n","  def __call__(self, x):\n","    return self.forward(x)\n","  \n","  def forward(self, x):\n","    return sigmoid(np.matmul(x, self.w) + self.b)\n","  \n","  def compute_gradients(self, x, t):\n","    y = self.forward(x)\n","    delta = y - t\n","    dw = np.matmul(x.T, delta)\n","    db = np.matmul(np.ones(x.shape[0]), delta)\n","    return dw, db\n","\n","def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","if __name__ == '__main__':\n","  np.random.seed(1234)\n","\n","  '''\n","  1. データの準備\n","  '''\n","  #OR\n","  x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","  t = np.array([0 , 1 , 1 , 1])\n","  '''\n","  2. モデルの構築\n","  '''\n","  model = LogisticRegression(input_dim=2)\n","  '''\n","  3. モデルの学習\n","  '''\n","  def compute_loss(t, y):\n","    return (-t * np.log(y) - (1 - t) * np.log(1 - y)).sum()\n","  \n","  def train_step(x, t):\n","    dw, db = model.compute_gradients(x, t)\n","    model.w = model.w - 0.1 * dw\n","    model.b = model.b - 0.1 * db\n","    loss = compute_loss(t, model(x))\n","    return loss\n","\n","  epochs = 100\n","\n","  for epoch in range(epochs):\n","    train_loss = train_step(x, t) #パッチ学習\n","\n","    if epoch % 10 == 0 or epoch == epochs - 1:\n","      print('epoch: {}, loss: {: .3f}' .format(epoch+1, train_loss))\n","  '''\n","  4. モデルの評価\n","  '''\n","  for input in x :\n","    print('{} => {: .3f}'.format(input, model(input)))\n","\n","\n","\n","\n","\n"]}]}